## 2.3 几何阶段

运行在gpu中的几何阶段负责大部分的逐三角形或逐顶点的计算。此阶段从功能上可分为：顶点着色，投影，裁剪，屏幕映射。见图2.3。

> 图2.3 几何阶段被分为这4个阶段

### 2.3.1 顶点着色

此阶段有两个目标：1是计算所有顶点的位置，2是计算任何程序员想计算的顶点上的数据，例如法向量或者贴图坐标。
传统地做法是，物体的着色是由它的每个顶点的位置、法向量，再根据光照计算得来，并且顶点上就存算得的颜色数据，后续步骤把顶点上的颜色插值到每个像素。
因此，可编程的顶点着色计算单元又称为顶点着色器。在现在的gpu里，所有的着色都是逐像素的，顶点着色阶段不用负责着色方程的计算了，而是变得非常通用。
现在这个阶段只是处理关联在逐顶点的数据。比如使用[4.4]()的方法，可以使用此阶段给一个物体实现动画的效果。

首先介绍位置如何计算，物体从一开始到最后到屏幕上画处理，中间涉及好几个空间，或者说好几个坐标系。
一开始模型在自己的*模型空间*里。
不同模型之间通过*模型变换*关联起来。一个模型可以关联多个这样的变换。这用来实现一个模型对应多个实例的功能。实例可以放在不同的位置上，拥有不同的大小，旋转，而避免复制模型自身数据。

模型变换要变的是模型的顶点和法向量。物体一开始叫做处于模型坐标系，把变换应用上之后，物体就处于世界坐标系，或者说世界空间。世界空间只有一个，模型们都变换完后，就同处于这一个世界空间内。

如前文所述，只有相机看到的东西需要被渲染。相机在世界空间中有位置和朝向。为了解决投影和裁剪，对相机和所有模型要进行*观察变换*。这个变换的目的是把相机放到原点，让它对着负z轴方向拍摄，然后正y方向是上面，正x是右手边。这里使用负z方向，也有使用正z方向的，两种没什么大差别，相互变换也很容易。这里使用哪种位置和方向的定义取决于实际的图形api。这个空间被称作*相机空间*，或者*观察空间*，*eye space（译注：不译）*。图2.4展示了一个定义的例子。模型变换和观察变换的实现都是使用4x4的矩阵，在[c4]()会介绍。我们一定要理解的是，顶点的位置和法向量是程序员想算成多少就能算成多少的。

> 图2.4 懒译，反正展示了最后的相机空间是怎么摆的。

接下来我们要介绍顶点着色的另一个输出。为了渲染出真实场景效果，只渲染物体的位置和形状是不够的，还要考虑他们的外观特性。具体需要考虑每个物体的材质，以及所有光源是如何影响到这个物体的。材质和光照可以用好多方法来建模，简单的可以只是颜色，复杂的可以是某种物理特性的表述。

决定材质和光照产生的效果的步骤叫做*着色*。着色需要在物体的各个点上计算一个*着色方程*。一般来说，这个计算的一部分在几何阶段进行，也有一些在逐像素的阶段进行。很多材质信息可以逐顶点存储，例如位置，法向量，颜色，及其他着色计算需要的数值。顶点着色的结果（包含颜色，向量，材质坐标等数据）传送到像素阶段，插值到像素，然后计算最终表面的着色。

本书[c3]()和[c5]()会深入介绍以gpu顶点着色器来表示的顶点着色。

顶点着色中会进行*投影*和*裁剪*，这两步把观察内的体积（译注：以前说的平截头体）变换成一个单位立方体，坐标从`(-1,-1,-1)`到`(1,1,1)`。这个范围也是随意定义的，比如z可以定义成从0到1。这个立方体叫做*规范化的观察体积*（译注：从空间的角度，《引架》里叫齐次裁剪空间）。两个步骤里先进行投影，在gpu里通过顶点着色器进行。一般有两种投影方式，*正交投影*和*透视投影*。如图2.5。正交投影又常被称作平行投影，但是它只是平行投影中的一种。建筑领域还常用其他的一些种，具体懒译。

注意投影也是用矩阵表示的（[4.7]()），因此它可以跟其他的几何变换先结合运算。

正交投影的观察体积是个长方体，正交投影变换把它变换成单位立方体。正交投影的特征是平行线变换后还是平行线。这个变换就是个位移和缩放的组合。

透视投影稍复杂。投影后有近大远小的效果。平行线在视平线处出现灭点。这模仿了人眼感知事物的方式。透视投影的观察体积是平截头体，它也是被变换到单位立方体。两种透视变换都可以用4x4矩阵表示（见[c4]()）。变换完后模型就在*裁剪坐标系*里。它是个齐次坐标系，也是[c4]()会介绍。这一步发生在除以w之前，为了后续功能步骤和裁剪能正常工作，顶点着色器的输出必须是这个类型的（译注：vec4）。

虽然这些变换是把体积变成另一个体积，但是因为后面z轴信息不是存储在图片里，而是在一个叫z缓冲的地方，所以模型还是从3维投影成了2维。z缓冲在[2.5](./2.5.md)中介绍。

### 2.3.2

每个流水线都得有上述的顶点处理功能。上述步骤完成后，gpu上还有一些其他功能可选。细分曲面，几何着色，流输出。是否使用他们取决于硬件是否支持，以及程序员是否想用。通常这些功能是不用的。详见[c3]()。

第一个可选阶段是细分曲面。假设你要画一个球，你会用一些三角形面来表示它。但是马上就会陷入性能和效果的两难之中。如果面数太少，球在近处看就很糙，如果面数很多，性能就受不了。使用细分曲面功能可以对区面生成合适数量的面。

之前我们提到了三角形，以及目前为止我们只谈了用流水线处理三角形。实际上它还能处理点，线，三角形，和其他东西。顶点数据可以用来描述一个曲面。
这样的平面可以由一组patch（译注：不会翻）定义，每个patch由一组顶点来定义。
细分曲面这一步骤本身可分为若干个步骤：hull着色器（译注，不会翻），细分曲面器，domain着色器。他们把patch顶点数据转换成（一般来说更多）顶点数据，然后用来生成三角形。相机的距离影响生成三角形的数量：近的时候多，远的时候少。

下一个可选阶段是几何着色器。它比细分曲面出现得更早，所以在gpu中也更常见支持。它像细分曲面一样，也是输入某种图元，然后生成新的顶点数据。它更简单一些，对顶点的创建的范围有限（？），可以生成的图元类型也有限得多。它的若干中用途中，最常见的一个是粒子生成。假设要模拟烟花爆炸，每个火球用一个顶点代表。几何着色器可以把每个点转化成一个面向屏幕的方形（两个三角形）。这就提供了一种更靠谱的图元给程序员来给它着色。

最后一个可选阶段叫做流输出。这可以让我们把gpu当作顶点生成器。我们可以关掉后面的绘制步骤，把处理过的顶点当作数组传输出来，供其他使用。数据可以被cpu使用，也可以再被gpu使用。这个步骤的典型用法也是粒子模拟，如之前说的烟花模拟。

这3个步骤的执行顺序是这样的：细分曲面，几何着色，流输出。每个阶段都是可选的。不论如何，现在我们有了在齐次空间内的一堆顶点数据了。接下来我们可以检查他们能不能被相机看到。

### 2.3.3 裁剪

只有全部或部分在观察体积内的图元会传给光栅化阶段，然后画到屏幕上。完全在外面的图元就被丢弃了。需要被裁剪的是部分在里面的图元。例如一根线有个顶点在外面，就应该裁剪一下，外面的点被丢弃，线段与体积边界的交点会成为这个线段的新顶点。之前的投影步骤等使得裁剪永远在单位立方体上面执行，使裁剪问题变成一个固定的问题。

裁剪可见图2.6的示意。此外，除了使用这6个面来裁剪之外，用户也可以自定义平面来显式地分割物体，这种操作叫做切片，见图19.1，第818页。

裁剪使用投影阶段产生的4维的齐次坐标系。在透视空间里裁剪的位置计算不能用简单的线性插值，第4个维度就是为了解决这个问题而存在的。最后会执行*透视除法*，把结果的三角形位置转换到3维*归一化的设备坐标系*。之前提到过，观察体积的范围是`(-1, -1, -1)`到`(1, 1, 1)`。最后一步会把这个范围转换到窗口坐标里。

### 2.3.4 屏幕映射

只有观察体积内的图元进入此阶段，此时坐标还是3维的。x和y坐标被转换成*屏幕坐标*。带z坐标的屏幕坐标也被称作*窗口坐标*。假设场景会被渲染到屏幕上从`(x1, y1)`到`(x2, y2)`的范围内。那么屏幕映射就是平移加缩放操作的组合。新的x和y就是屏幕坐标，z也被映射到某个范围`[z1, z2]`。默认z1是0，z2是1。不同api可能不同。之后窗口坐标传入光栅化阶段。
屏幕映射见图2.7示意。

接下来介绍和像素有关的整型和浮点数值运算。给一行笛卡尔坐标系内的像素，最左像素的左边的x坐标在浮点数表示下是0.0。opengl一直用这种表示，dx10也沿用了。像素的中心点是0.5位置。所以从0到9这10个像素的覆盖范围是`[0.0, 10.0)`。转换方式如下：

\\[ d = floor(c) \\]
\\[ c = d + 0.5 \\]

d是像素的编号（整形），c是像素内连续的位置（浮点）。

所有api的水平坐标都是从左往右增长的，但是上下方向不同api有不同。opengl使用笛卡尔坐标，左下角的坐标是最小的。dx优势把左上定义为坐标最小的。比如`(0, 0)`在opengl里是图片的左下角，在dx里是左上角。程序更换api的时候这个区分要特殊注意。